setwd("/extra/tmp/mffk55/Dropbox/Bayesian_statistics_3_4/Bayesian_statistics_2017-2018/Applets/Bayesian_Statistics")
rsconnect::deployApp('./demo_PointEstimation/demo_PointEstimation.Rmd',account ='georgios-stats-1')
rsconnect::deployApp('./demo_PointEstimation/demo_PointEstimation.Rmd',account ='georgios-stats-1')
rsconnect::deployApp('./demo_PointEstimation/demo_PointEstimation.Rmd',account ='georgios-stats-1')
rsconnect::deployApp('./demo_PointEstimation/demo_PointEstimation.Rmd',account ='georgios-stats-1')
setwd("~/Downloads")
setwd("/extra/tmp/mffk55/Dropbox/Teaching/2019.term1.Bayesian_statistics_3_4/GitHub/Bayesian_Statistics")
read.csv('https://github.com/georgios-stats/Bayesian_Statistics/blob/master/ComputerPracticals/scripts/nissan.csv')
?read.csv
read.csv('https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/nissan.csv')
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
mydata
setwd("/extra/tmp/mffk55/Dropbox/Teaching/2019.term1.Bayesian_statistics_3_4/ComputerPractical")
setwd("/extra/tmp/mffk55/Dropbox/Teaching/2019.term1.Bayesian_statistics_3_4/ComputerPractical")
setwd("/extra/tmp/mffk55/Dropbox/Teaching/2019.term1.Bayesian_statistics_3_4/ComputerPractical")
?data
data(faithful)
hist(faithful)
hist(faithful[,1])
hist(faithful[,2])
mean(fafaifaithful)
mean(faithful)
mean(faithful[1:2])
mean(faithful[,1:2])
mean(faithful[,1])
mean(faithful[,2])
sd(faithful[,2])
sd(faithful[,1])
setwd('./ComputerPracticals/scripts/')
getwd()
install.packages('flexdashboard')
ls
ls()
install.packages('rknit')
install.packages('knitr')
library(knitr)
library(knitr)
rm(list=ls())
rm(list=ls())
# Load R package for printing
library(knitr)
library(kableExtra)
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://github.com/georgios-stats/Bayesian_Statistics/blob/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
rm(list=ls())
# Load R package for printing
library(knitr)
library(kableExtra)
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# Load rjags
library("rjags")
# Input parameters  : n, y, a_0, b_0
# output parameters : p
hierarhicalmodel <- "
model {
# this is related tot he sampling distribution
for ( i in 1 : n ) {
y[ i ] ~ dbern( p )
}
# this is related to the prior distributions
p ~ dbeta( a_0 , b_0 )
}
"
y_obs <- mydata[ -nrow(mydata) , 4 ] # exclude the last row, and use only the 4th column
y_obs <- as.numeric( y_obs == 1 )    # make it numeric
n_obs <- length( y_obs )
a_0 <- 1.0
b_0 <- 1.0
data.bayes <- list(y = y_obs,
n = n_obs,
a_0 = a_0,
b_0 = b_0)
model.smpl <- jags.model( file = textConnection(hierarhicalmodel),
data = data.bayes)
adapt( object = model.smpl,
n.iter = 1000 )
N = 10000      # the size of the sample we ll gonna get
output = jags.samples( model= model.smpl,          # the model
variable.names= c("p"),    # names of variables to be sampled
n.iter = N                # size of sample
)
save.image(file="BernoulliModel.RData")
names(output)
dim( output$p )
# the first dimension is the numbers of columns of the variable
# the second dimention is the size of the sample drawn
# the third dimension is the number of the sub-samples drawn (in our case it is just 1)
pr.smpl <-output$p
# extract the sample from the jags object
pr.smpl <-pr.smpl[1,,]
# draw the trace plots
z <- pr.smpl
plot(z,
type = "l",
main = "Trace plot of p",
xlab = "iteration",
ylab = "p",
ylim = c(-0.1,1.1)
)
# Draw the histogram as the MC approximate of the CDF
z <- pr.smpl
x_plot <- seq( from = 0.001, to = 0.999, length.out = 100)
y_plot <- rep(NaN, 100)
for (i in 1:100) y_plot[i] <- mean(z<=x_plot[i])
plot(x_plot,
y_plot,
type = "l",
main = "CDF of p",
xlab = "p",
ylab = "CDF")
# Draw the Exact CDF
a_n = a_0+n_obs*mean(y_obs)
b_n = b_0+n_obs-n_obs*mean(y_obs)
x_plot <- seq( from = 0.001, to = 0.999, length.out = 100)
y_plot <- pbeta(x_plot, a_n, b_n )
lines( x_plot,
y_plot,
col = 'red'
)
# Create a legend
legend("topright",
legend=c("MC approx.", "Exact"),
lty = c(1,1),
col=c("black", "red"))
# Draw the histogram as the MC approximate of the PDF
z <- pr.smpl
hist(z,
probability = TRUE,
main = "Density of p",
xlab = "p",
ylab = "PDF")
# Draw the Exact PDF
a_n = a_0+n_obs*mean(y_obs)
b_n = b_0+n_obs-n_obs*mean(y_obs)
x_plot <- seq( from = 0.001, to = 0.999, length.out = 100)
y_plot <- dbeta(x_plot, a_n, b_n )
lines( x_plot,
y_plot,
col = 'red'
)
# Create a legend
legend("topright",
legend=c("MC approx.", "Exact"),
lty = c(1,1),
col=c("black", "red"))
# Draw the histogram as the MC approximate of the PDF
z <- pr.smpl
Pr.p.mc <- 1-mean(z<=0.5)
Pr.p.mc
a_n = a_0+n_obs*mean(y_obs)
b_n = b_0+n_obs-n_obs*mean(y_obs)
Pr.p.ex <- 1- pbeta(0.5, a_n, b_n)
Pr.p.ex
z <- pr.smpl
CI.mc <- quantile(z, probs = c(0.025, 0.0975))
CI.mc
a_n <- a_0+n_obs*mean(y_obs)
b_n <- b_0+n_obs-n_obs*mean(y_obs)
CI.exact <- qbeta(c(0.025, 0.0975),
shape1 = a_n,
shape2 = b_n)
CI.exact
# Draw the histogram as the MC approximate of the PDF
z <- pr.smpl
E_mc <- mean(z)
print(E_mc)
a_n <- a_0+n_obs*mean(y_obs)
b_n <- b_0+n_obs-n_obs*mean(y_obs)
E_exact <- a_n / (a_n+b_n)
print(E_exact)
# Draw the histogram as the MC approximate of the PDF
z <- pr.smpl
theta <- z/(1-z)
E_mc <- mean(z)
print(E_mc)
a_n <- a_0+n_obs*mean(y_obs)
b_n <- b_0+n_obs-n_obs*mean(y_obs)
E_exact <-a_n/(b_n-1)
print(E_exact)
par(mfrow=c(1,2))
# Draw the histogram as the MC approximate of the PDF
z <- pr.smpl
pmf_y_new_0.mc <- 1-mean(z)
pmf_y_new_1.mc <- mean(z)
## draw
barplot( c(pmf_y_new_0.mc , pmf_y_new_1.mc),
names.arg= c('0','1'),
main = "MC approx. PMF of y_new",
xlab = "y_new",
ylab = "P(y_new|y_{1:n})",
ylim = c(0,1))
# Draw the histogram as the Exact of the PDF
## compute
a_n = a_0+n_obs*mean(y_obs)
b_n = b_0+n_obs-n_obs*mean(y_obs)
pmf_y_new_0 <- beta(a_n+0,b_n+1-0) / beta(a_n,b_n)
pmf_y_new_1 <- beta(a_n+1,b_n+1-1) / beta(a_n,b_n)
## draw
barplot( c(pmf_y_new_0,pmf_y_new_1),
names.arg= c('0','1'),
main = "Exact PMF of y_new",
xlab = "y_new",
ylab = "P(y_new|y_{1:n})",
ylim = c(0,1))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./challenger_data.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/challenger_data.csv")
# print data
## (that's a sophisticated command with fancy output, feel free to ignore it)
kable(mydata)%>%
kable_styling(bootstrap_options = c("striped", "hover"))
# load the data
#mydata <- read.csv("./nissan.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/nissan.csv")
#mydata$mpg <- rnorm(100, 20, 5)
# print data
cat(mydata$mpg)
# load the data
#mydata <- read.csv("./nissan.csv")
mydata <- read.csv("https://raw.githubusercontent.com/georgios-stats/Bayesian_Statistics/master/ComputerPracticals/scripts/nissan.csv")
# print data
cat(mydata$mpg)
webshot::install_phantomjs()
webshot::install_phantomjs()
# Load R package for printing
library(knitr)
library(kableExtra)
install.packages("webshot")
webshot::install_phantomjs()
install.packages("webshot")
webshot::install_phantomjs()
setwd("~/Dropbox/Teaching/2019.term1.Bayesian_statistics_3_4/ComputerPractical")
